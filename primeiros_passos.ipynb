{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeiros passos com PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste Objeto de Aprendizagem daremos nossos primeiros passos com o PySpark e Spark Dataframes. O objetivo aqui √© conhecer os principais objetos do PySpark e introduzir os m√©todos mais b√°sicos para familiarizar com a tecnologia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come√ßaremos pela importa√ß√£o do pacote do PySpark que engloba as opera√ß√µes com DataFrames e ent√£o criaremos um pequeno DataFrame que ser√° utilizado nos exemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas necess√°rias\n",
    "\n",
    "Por enquanto precisaremos somente do m√≥dulo `pyspark.sql`. O pacote PySpark possui diversos m√≥dulos, mas por enquanto precisaremos somente dos objetos que est√£o em `pyspark.sql`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-40b33c5464ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Uso do Spark Dataframes no PySpark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "# Uso do Spark Dataframes no PySpark\n",
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conectando com o Spark\n",
    "\n",
    "O pr√≥ximo passo √© iniciar uma sess√£o do Spark (`SparkSession`), cujo papel √© o de comunica√ß√£o com o Cluster. No exemplo abaixo criaremos uma sess√£o local - ou seja, com um minicluster na sua pr√≥pria m√°quina. Esta sess√£o local √© definida por meio do m√©todo `master`. O m√©todo `master` indica qual o tipo de Cluster onde conectaremos e outros detalhes. \n",
    "\n",
    "No nosso caso indicamos que o tipo de Cluster √© local e que este utilizaremos 2 processadores para execu√ß√£o das tarefas do Spark. Percebam que mesmo em modo local temos √† nossa disposi√ß√£o a capacidade de processamento _multicore_.\n",
    "\n",
    "**IMPORTANTE**: No ambiente da **Databricks** n√£o precisamos criar uma Sess√£o pois o notebook ser√° vinculado (_attached_) a um cluster no momento da execu√ß√£o. Logo, o bloco de c√≥digo abaixo n√£o ser√° necess√°rio **na Databricks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos trabalhar com o Spark localmente, sem o uso de um cluster.\n",
    "#spark = SparkSession \\\n",
    "#    .builder \\\n",
    "#    .master(\"local[2]\") \\\n",
    "#    .appName(\"Primeiros passos\") \\\n",
    "#    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria√ß√£o de um Data Frame via c√≥digo\n",
    "\n",
    "Nesta sess√£o criaremos um DataFrame diretamente via c√≥digo. Esta n√£o √© uma pr√°tica muito comum, visto que trabalhamos com grandes volumes de dados obtidos atrav√©s de Sistemas de Armazenamento. \n",
    "\n",
    "Mas n√£o pensem que a cria√ß√£o de um DataFrame via c√≥digo s√≥ serve para exemplos! Ainda veremos casos onde esta pr√°tica ajudar√° na resolu√ß√£o de problemas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo Pr√°tico\n",
    "\n",
    "Nosso exemplo pr√°tico utiliza a rela√ß√£o de disciplinas que comp√µe esta especializa√ß√£o e suas cargas hor√°rias!\n",
    "\n",
    "Os dados para este exemplo foram obtidos **manualmente** da p√°gina de Estrutura Curricular do curso, dispon√≠vel [aqui](http://www.unisinos.br/especializacao/big-data-data-science-e-data-analytics/ead/sao-leopoldo/estrutura-curricular)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defini√ß√£o da estrutura: Registros e Colunas\n",
    "\n",
    "Para criar um DataFrame por c√≥digo precisamos inicialmente definir sua estrutura. A linha de c√≥digo abaixo define que nosso DataFrame ser√° formado por disciplinas, onde cada registro (**Row**) ser√° uma disciplina. Os atributos de uma disciplina dispon√≠veis ser√£o o _nome_ e a _carga hor√°ria_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Estrutura do nosso DataFrame\n",
    "Disciplina = Row(\"nome\", \"carga_horaria\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria√ß√£o de inst√¢ncias (registros e atributos)\n",
    "\n",
    "Nosso pr√≥ximo passo √© a cria√ß√£o de inst√¢ncias para popular o DataFrame. Usaremos a estrutura `Disciplina` rec√©m criada para instanciar cada uma das disciplinas da especializa√ß√£o e sua carga hor√°ria. \n",
    "\n",
    "Neste exemplo foi criada uma refer√™ncia (`d01` a `d14`) por disciplina para deixar o c√≥digo mais claro. No passo seguinte criaremos uma lista que agrupar√° todas as disciplinas e servir√° de fonte para envio dos dados ao Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cada uma das disciplinas da especializa√ß√£o √© criada como uma inst√¢ncia do registro Disciplina.\n",
    "\n",
    "d01 = Disciplina(\"Introdu√ß√£o a BigData e Analytics\", 36)\n",
    "d02 = Disciplina(\"Estat√≠stica aplicada\", 24)\n",
    "d03 = Disciplina(\"Visualiza√ß√£o de dados e informa√ß√£o\", 24)\n",
    "d04 = Disciplina(\"Compartilhamento e seguran√ßa de dados\", 24)\n",
    "d05 = Disciplina(\"Introdu√ß√£o a Python e linguagem R\", 36)\n",
    "d06 = Disciplina(\"Machine Learning\", 24)\n",
    "d07 = Disciplina(\"Processamento de Alto Desempenho e Aplica√ß√µes\", 24)\n",
    "d08 = Disciplina(\"Lidando com BigData: Apache Spark, Hadoop, MapReduce, Hive\", 24)\n",
    "d09 = Disciplina(\"Gerenciamento e Processamento de grande volume de dados\", 24)\n",
    "d10 = Disciplina(\"Internet das Coisas e Aplica√ß√µes Distribu√≠das\", 24)\n",
    "d11 = Disciplina(\"Deep Learning\", 24)\n",
    "d12 = Disciplina(\"Business Intelligence e BigData\", 24)\n",
    "d13 = Disciplina(\"Atividades Integradoras\", 12)\n",
    "d14 = Disciplina(\"Prepara√ß√£o para Projeto Aplicado\", 36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por meio da fun√ß√£o `display` temos uma pr√©via do que ser√° nosso DataFrame! Atentem para o fato de que at√© aqui nossos dados est√£o no Python e n√£o no Spark. Ainda n√£o temos um DataFrame!\n",
    "\n",
    "No ambiente **Databricks** o resultado da fun√ß√£o `display` ser√° apresentado de forma mais amig√°vel pois o mecanismo de notebooks do ambiente est√° preparado para formata√ß√£o dos objetos Row do Spark. L√° a visualiza√ß√£o da lista `Row` e posteriormente do DataFrame ser√£o muito parecidas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>nome</th><th>carga_horaria</th></tr></thead><tbody><tr><td>Introdu√ß√£o a BigData e Analytics</td><td>36</td></tr><tr><td>Estat√≠stica aplicada</td><td>24</td></tr><tr><td>Visualiza√ß√£o de dados e informa√ß√£o</td><td>24</td></tr><tr><td>Compartilhamento e seguran√ßa de dados</td><td>24</td></tr><tr><td>Introdu√ß√£o a Python e linguagem R</td><td>36</td></tr><tr><td>Machine Learning</td><td>24</td></tr><tr><td>Processamento de Alto Desempenho e Aplica√ß√µes</td><td>24</td></tr><tr><td>Lidando com BigData: Apache Spark, Hadoop, MapReduce, Hive</td><td>24</td></tr><tr><td>Gerenciamento e Processamento de grande volume de dados</td><td>24</td></tr><tr><td>Internet das Coisas e Aplica√ß√µes Distribu√≠das</td><td>24</td></tr><tr><td>Deep Learning</td><td>24</td></tr><tr><td>Business Intelligence e BigData</td><td>24</td></tr><tr><td>Atividades Integradoras</td><td>12</td></tr><tr><td>Prepara√ß√£o para Projeto Aplicado</td><td>36</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "especializacao_bigdata_datascience = [d01, d02, d03, d04, d05, d06, d07, d08, d09, d10, d11, d12, d13, d14]\n",
    "\n",
    "display(especializacao_bigdata_datascience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria√ß√£o do DataFrame por meio da transfer√™ncia dos dados da lista\n",
    "\n",
    "Lembram que mais acima eu descrevi o `SparkSession` como o canal de comunica√ß√£o com o Cluster? Pois bem, agora veremos na pr√°tica o que isso significa. Nossa sess√£o possibilita a cria√ß√£o de um DataFrame pelo m√©todo `createDataFrame`. Este m√©todo:\n",
    "- envia a lista de objetos `Row` para o Cluster\n",
    "- cria uma estrutra de DataFrame no Cluster\n",
    "- popula o DataFrame com os objetos `Row` recebidos\n",
    "- retorna a refer√™ncia ao DataFrame para o Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_especializacao = spark.createDataFrame(especializacao_bigdata_datascience)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voltaremos a usar a fun√ß√£o `display`, desta vez para inspecionar o conte√∫do da refer√™ncia ao DataFrame que o m√©todo `createDataFrame` retornou para n√≥s. Aqui percebemos que se trata de um DataFrame, e que ele possui duas colunas:\n",
    "\n",
    "- nome: string\n",
    "- carga_horaria: bigint\n",
    "\n",
    "**Importante**: Na **Databricks** a fun√ß√£o `display` exibe o conte√∫do do nosso DataFrame de forma bastante similar a quando usamos `display` para visualizar o conte√∫do da lista de objetos `Row`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>nome</th><th>carga_horaria</th></tr></thead><tbody><tr><td>Introdu√ß√£o a BigData e Analytics</td><td>36</td></tr><tr><td>Estat√≠stica aplicada</td><td>24</td></tr><tr><td>Visualiza√ß√£o de dados e informa√ß√£o</td><td>24</td></tr><tr><td>Compartilhamento e seguran√ßa de dados</td><td>24</td></tr><tr><td>Introdu√ß√£o a Python e linguagem R</td><td>36</td></tr><tr><td>Machine Learning</td><td>24</td></tr><tr><td>Processamento de Alto Desempenho e Aplica√ß√µes</td><td>24</td></tr><tr><td>Lidando com BigData: Apache Spark, Hadoop, MapReduce, Hive</td><td>24</td></tr><tr><td>Gerenciamento e Processamento de grande volume de dados</td><td>24</td></tr><tr><td>Internet das Coisas e Aplica√ß√µes Distribu√≠das</td><td>24</td></tr><tr><td>Deep Learning</td><td>24</td></tr><tr><td>Business Intelligence e BigData</td><td>24</td></tr><tr><td>Atividades Integradoras</td><td>12</td></tr><tr><td>Prepara√ß√£o para Projeto Aplicado</td><td>36</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_especializacao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualiza√ß√£o de dados de um DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M√©todo `show`\n",
    "\n",
    "O m√©todo `show` exibe registros do DataFrame formatados em modo texto. Se a chamada ao m√©todo for sem nenhum par√¢metro ele retornar√° uma tabela com os nomes das coluns em cabe√ßalho, registros at√© um m√°ximo de 20 linhas e os valores das colunas de tipo String (texto) ser√£o exibidos at√© um m√°ximo de 20 caracteres.\n",
    "\n",
    "A documenta√ß√£o do m√©todo `show` ([link](http://spark.apache.org/docs/2.4.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame.show)) detalha os seguintes par√¢metros:\n",
    "\n",
    "- **n** ‚Äì N√∫mero de registros a exibir. Se quisermos uma quantidade diferente de 20 registros ent√£o devemos informar a quantidade neste par√¢metro.\n",
    "- **truncate** ‚Äì Se 20 caracteres for pouco (e no nosso exemplo vimos que √© pouco) ent√£o devemos informar quantos caracteres das colunas String devem ser mostrados. Se o DataFrame tiver muitas colunas do tipo String a visualiza√ß√£o pode ficar dif√≠cil.\n",
    "- **vertical** ‚Äì Se for False (padr√£o), exibe em formato de tabela. Se for True, exibir√° cada coluna em uma linha, em formato de lista de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------------------+-------------+\n",
       "                nome|carga_horaria|\n",
       "+--------------------+-------------+\n",
       "Introdu√ß√£o a BigD...|           36|\n",
       "Estat√≠stica aplicada|           24|\n",
       "Visualiza√ß√£o de d...|           24|\n",
       "Compartilhamento ...|           24|\n",
       "Introdu√ß√£o a Pyth...|           36|\n",
       "    Machine Learning|           24|\n",
       "Processamento de ...|           24|\n",
       "Lidando com BigDa...|           24|\n",
       "Gerenciamento e P...|           24|\n",
       "Internet das Cois...|           24|\n",
       "       Deep Learning|           24|\n",
       "Business Intellig...|           24|\n",
       "Atividades Integr...|           12|\n",
       "Prepara√ß√£o para P...|           36|\n",
       "+--------------------+-------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_especializacao.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">-RECORD 0-------------------------------------------------------------------\n",
       " nome          | Introdu√ß√£o a BigData e Analytics                           \n",
       " carga_horaria | 36                                                         \n",
       "-RECORD 1-------------------------------------------------------------------\n",
       " nome          | Estat√≠stica aplicada                                       \n",
       " carga_horaria | 24                                                         \n",
       "-RECORD 2-------------------------------------------------------------------\n",
       " nome          | Visualiza√ß√£o de dados e informa√ß√£o                         \n",
       " carga_horaria | 24                                                         \n",
       "-RECORD 3-------------------------------------------------------------------\n",
       " nome          | Compartilhamento e seguran√ßa de dados                      \n",
       " carga_horaria | 24                                                         \n",
       "-RECORD 4-------------------------------------------------------------------\n",
       " nome          | Introdu√ß√£o a Python e linguagem R                          \n",
       " carga_horaria | 36                                                         \n",
       "-RECORD 5-------------------------------------------------------------------\n",
       " nome          | Machine Learning                                           \n",
       " carga_horaria | 24                                                         \n",
       "-RECORD 6-------------------------------------------------------------------\n",
       " nome          | Processamento de Alto Desempenho e Aplica√ß√µes              \n",
       " carga_horaria | 24                                                         \n",
       "-RECORD 7-------------------------------------------------------------------\n",
       " nome          | Lidando com BigData: Apache Spark, Hadoop, MapReduce, Hive \n",
       " carga_horaria | 24                                                         \n",
       "-RECORD 8-------------------------------------------------------------------\n",
       " nome          | Gerenciamento e Processamento de grande volume de dados    \n",
       " carga_horaria | 24                                                         \n",
       "-RECORD 9-------------------------------------------------------------------\n",
       " nome          | Internet das Coisas e Aplica√ß√µes Distribu√≠das              \n",
       " carga_horaria | 24                                                         \n",
       "-RECORD 10------------------------------------------------------------------\n",
       " nome          | Deep Learning                                              \n",
       " carga_horaria | 24                                                         \n",
       "-RECORD 11------------------------------------------------------------------\n",
       " nome          | Business Intelligence e BigData                            \n",
       " carga_horaria | 24                                                         \n",
       "-RECORD 12------------------------------------------------------------------\n",
       " nome          | Atividades Integradoras                                    \n",
       " carga_horaria | 12                                                         \n",
       "-RECORD 13------------------------------------------------------------------\n",
       " nome          | Prepara√ß√£o para Projeto Aplicado                           \n",
       " carga_horaria | 36                                                         \n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lista de registros, exibindo os primeiros 60 caracteres de cada nome.\n",
    "df_especializacao.show(vertical=True, truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----------------------------------+-------------+\n",
       "                              nome|carga_horaria|\n",
       "+----------------------------------+-------------+\n",
       "  Introdu√ß√£o a BigData e Analytics|           36|\n",
       "              Estat√≠stica aplicada|           24|\n",
       "Visualiza√ß√£o de dados e informa√ß√£o|           24|\n",
       "+----------------------------------+-------------+\n",
       "only showing top 3 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Somente 5 registros\n",
    "df_especializacao.show(n=3, truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M√©todos `describe` e `summary`\n",
    "\n",
    "O m√©todo `describe` computa estat√≠sticas descritivas b√°sicas nas colunas num√©ricas e textuais. √â utilizado em conjunto com o m√©todo `show` para exibi√ß√£o do resultado.\n",
    "\n",
    "**Aten√ß√£o**: Esta opera√ß√£o pode ser bastante demorada em um DataFrame de maior volume. O motivo ficar√° claro ao longo da disciplina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-------+----------------------------------+------------------+\n",
       "summary|                              nome|     carga_horaria|\n",
       "+-------+----------------------------------+------------------+\n",
       "  count|                                14|                14|\n",
       "   mean|                              null|25.714285714285715|\n",
       " stddev|                              null|6.4142698058981855|\n",
       "    min|           Atividades Integradoras|                12|\n",
       "    max|Visualiza√ß√£o de dados e informa√ß√£o|                36|\n",
       "+-------+----------------------------------+------------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_especializacao.describe().show(truncate=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J√° o m√©todo `summary` computa algumas estat√≠sticas a mais, os quantis. Sem informar par√¢metros, summary ir√° calcular os quantis 25%, 50% (mediana) e 75%. O par√¢metro de `summary` possiblita escolher quais estat√≠sticas ser√£o calculadas.\n",
    "\n",
    "As estat√≠sticas dispon√≠veis est√£o descritas na documenta√ß√£o do m√©todo ([link](http://spark.apache.org/docs/2.4.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame.summary)).\n",
    "\n",
    "**O mesmo alerta e tempo de processamento segue v√°lido**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-------+----------------------------------+------------------+\n",
       "summary|                              nome|     carga_horaria|\n",
       "+-------+----------------------------------+------------------+\n",
       "  count|                                14|                14|\n",
       "   mean|                              null|25.714285714285715|\n",
       " stddev|                              null|6.4142698058981855|\n",
       "    min|           Atividades Integradoras|                12|\n",
       "    25%|                              null|                24|\n",
       "    50%|                              null|                24|\n",
       "    75%|                              null|                24|\n",
       "    max|Visualiza√ß√£o de dados e informa√ß√£o|                36|\n",
       "+-------+----------------------------------+------------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_especializacao.summary().show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-------+----+------------------+\n",
       "summary|nome|     carga_horaria|\n",
       "+-------+----+------------------+\n",
       "  count|  14|                14|\n",
       "   mean|null|25.714285714285715|\n",
       "    10%|null|                24|\n",
       "    50%|null|                24|\n",
       "    90%|null|                36|\n",
       "+-------+----+------------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_especializacao.summary(\"count\", \"mean\", \"10%\", \"50%\", \"90%\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M√©todo `columns`\n",
    "\n",
    "Retorna uma lista com os nomes das colunas do DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[13]: [&#39;nome&#39;, &#39;carga_horaria&#39;]</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_especializacao.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M√©todo count\n",
    "\n",
    "Retorna a quantidade de registros de um DataFrame.\n",
    "\n",
    "**Aten√ß√£o**: Por mais que n√£o pare√ßa intuitivo, este opera√ß√£o pode ser bastante demorada em um DataFrame de maior volume, e novamente digo que o motivo ficar√° claro ao longo da disciplina!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[14]: 14</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_especializacao.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O caminho contr√°rio\n",
    "\n",
    "Da mesma forma como conseguimos enviar dados do Python para o Spark (üêç‚û°Ô∏èüí•) podemos tamb√©m trazer dados do Spark  para o Python (üêç‚¨ÖÔ∏èüí•).\n",
    "\n",
    "**Mas antes temos que conversar sobre volumes de dados.**\n",
    "\n",
    "> Neste Objeto de Aprendizagem estamos trabalhando com pequenos volumes de dados em ambiente local, ent√£o a transfer√™ncia de dados n√£o causar√° dores de cabe√ßa. No entanto, considerem o cen√°rio real de lidar com grandes volumes de dados em um cluster, em ordem de grandeza maior do que sua m√°quina √© capaz de armazenar em mem√≥ria. Pense em Terabytes (TB) de dados. Tentar transferir este volume de dados do cluster para sua m√°quina ser√° um desastre.\n",
    "\n",
    "Na pr√°tica, a transfer√™ncia de DataFrames do Spark para o Python √© feita ap√≥s algum processamento dos dados no Spark. Este processamento pode ser:\n",
    "- sumariza√ß√£o de dados (estat√≠sticas descritivas, agrupamentos)\n",
    "- a sele√ß√£o e filtro de um subconjunto de dados\n",
    "- amostragem\n",
    "- etc.\n",
    "\n",
    "E uma justificativa para transfer√™ncias deste tipo √© a necessidade de uso de recursos que n√£o est√£o dispon√≠veis no Spark. E mesmo assim temos formas de enviar recursos do Python para uso no Spark (faremos isso em outra oportunidade)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M√©todos `head`, `first` e `take`\n",
    "\n",
    "O m√©todo `head` retorna o **n** primeiros registros de um DataFrame, retornando somente 1 registro se o par√¢metro **n** n√£o for especificado.\n",
    "\n",
    "Uma pegadinha: Se n√£o especificar o par√¢metro, o objeto de retorno √© o primeiro registro, de tipo `Row`. No entanto, se especificar **n=1** o retorno ser√° de tipo `list` com o objeto `Row` dentro da lista. `head` sem par√¢metros √© equivalente ao m√©todo `first`.\n",
    "\n",
    "`take` √© bastante similar a `head`, por√©m com par√¢metro **num** obrigat√≥rio.\n",
    "\n",
    "Apesar da aparente confus√£o, pense que `head` √© uma combina√ß√£o de `first` e `take`:\n",
    "\n",
    "- `head` sem par√¢metro equivale a `first`\n",
    "- `head` com par√¢metro equivale a `take`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">(Row(nome=&#39;Introdu√ß√£o a BigData e Analytics&#39;, carga_horaria=36), &lt;class &#39;pyspark.sql.types.Row&#39;&gt;)\n",
       "([Row(nome=&#39;Introdu√ß√£o a BigData e Analytics&#39;, carga_horaria=36), Row(nome=&#39;Estat√≠stica aplicada&#39;, carga_horaria=24), Row(nome=&#39;Visualiza√ß√£o de dados e informa√ß√£o&#39;, carga_horaria=24), Row(nome=&#39;Compartilhamento e seguran√ßa de dados&#39;, carga_horaria=24), Row(nome=&#39;Introdu√ß√£o a Python e linguagem R&#39;, carga_horaria=36)], &lt;class &#39;list&#39;&gt;)\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "um = df_especializacao.head()\n",
    "lum = df_especializacao.head(n=5)\n",
    "\n",
    "print((um, type(um)))\n",
    "print((lum, type(lum)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[16]: Row(nome=&#39;Introdu√ß√£o a BigData e Analytics&#39;, carga_horaria=36)</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_especializacao.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[17]: [Row(nome=&#39;Introdu√ß√£o a BigData e Analytics&#39;, carga_horaria=36),\n",
       " Row(nome=&#39;Estat√≠stica aplicada&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Visualiza√ß√£o de dados e informa√ß√£o&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Compartilhamento e seguran√ßa de dados&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Introdu√ß√£o a Python e linguagem R&#39;, carga_horaria=36),\n",
       " Row(nome=&#39;Machine Learning&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Processamento de Alto Desempenho e Aplica√ß√µes&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Lidando com BigData: Apache Spark, Hadoop, MapReduce, Hive&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Gerenciamento e Processamento de grande volume de dados&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Internet das Coisas e Aplica√ß√µes Distribu√≠das&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Deep Learning&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Business Intelligence e BigData&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Atividades Integradoras&#39;, carga_horaria=12),\n",
       " Row(nome=&#39;Prepara√ß√£o para Projeto Aplicado&#39;, carga_horaria=36)]</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_especializacao.take(num=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M√©todo `collect`\n",
    "\n",
    "Este m√©todo retorna **todos** os registros do DataFrame. \n",
    "\n",
    "**Cuidado** ao usar este m√©todo com grandes volumes de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[18]: [Row(nome=&#39;Introdu√ß√£o a BigData e Analytics&#39;, carga_horaria=36),\n",
       " Row(nome=&#39;Estat√≠stica aplicada&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Visualiza√ß√£o de dados e informa√ß√£o&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Compartilhamento e seguran√ßa de dados&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Introdu√ß√£o a Python e linguagem R&#39;, carga_horaria=36),\n",
       " Row(nome=&#39;Machine Learning&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Processamento de Alto Desempenho e Aplica√ß√µes&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Lidando com BigData: Apache Spark, Hadoop, MapReduce, Hive&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Gerenciamento e Processamento de grande volume de dados&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Internet das Coisas e Aplica√ß√µes Distribu√≠das&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Deep Learning&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Business Intelligence e BigData&#39;, carga_horaria=24),\n",
       " Row(nome=&#39;Atividades Integradoras&#39;, carga_horaria=12),\n",
       " Row(nome=&#39;Prepara√ß√£o para Projeto Aplicado&#39;, carga_horaria=36)]</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_especializacao.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalizando a sess√£o\n",
    "\n",
    "Em muitos casos de uso o Cluster √© um ambiente compartilhado e de recursos finitos. Ao concluir o uso de uma sess√£o do Spark sempre √© recomendado finaliz√°-la para liberar os recursos alocados nesta sess√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "name": "primeiros_passos",
  "notebookId": 3892328798844911
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
